{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from inference_TTA import Inference, encode_mask_to_rle, load_ensemble_conf\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'run_name_format': 'ensemble_crop_{crop_type}_TTA_{TTA}_{n_models}-models',\n",
       " 'crop_type': 'arm',\n",
       " 'model_dir_path_formats': ['/data/ephemeral/home/Dongjin/level2-cv-semanticsegmentation-cv-02-lv3/Baseline/Dongjin/transformers_1124/trained_models/nvidia/mit-b2_crop_{crop_type}_fold0',\n",
       "  '/data/ephemeral/home/Dongjin/level2-cv-semanticsegmentation-cv-02-lv3/Baseline/Dongjin/transformers_1124/trained_models/openmmlab/upernet-convnext-small_crop_{crop_type}_fold0',\n",
       "  '/data/ephemeral/home/Dongjin/level2-cv-semanticsegmentation-cv-02-lv3/Baseline/Dongjin/transformers_1124/trained_models/openmmlab/upernet-swin-small_crop_{crop_type}_fold0'],\n",
       " 'TTA': True,\n",
       " 'model_dir_paths': ['/data/ephemeral/home/Dongjin/level2-cv-semanticsegmentation-cv-02-lv3/Baseline/Dongjin/transformers_1124/trained_models/nvidia/mit-b2_crop_arm_fold0',\n",
       "  '/data/ephemeral/home/Dongjin/level2-cv-semanticsegmentation-cv-02-lv3/Baseline/Dongjin/transformers_1124/trained_models/openmmlab/upernet-convnext-small_crop_arm_fold0',\n",
       "  '/data/ephemeral/home/Dongjin/level2-cv-semanticsegmentation-cv-02-lv3/Baseline/Dongjin/transformers_1124/trained_models/openmmlab/upernet-swin-small_crop_arm_fold0'],\n",
       " 'run_name': 'ensemble_crop_arm_TTA_True_3-models',\n",
       " 'save_dir_path': 'ensemble/ensemble_crop_arm_TTA_True_3-models',\n",
       " 'save_path': 'ensemble/ensemble_crop_arm_TTA_True_3-models/test_ensemble_crop_arm_TTA_True_3-models.csv'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir_path = \"\" #os.path.dirname(os.path.realpath(__file__))\n",
    "ensemble_conf_path = 'conf/ensemble/ensemble1.json'\n",
    "conf = load_ensemble_conf(work_dir_path, ensemble_conf_path)\n",
    "\n",
    "\n",
    "n_models = len(inferences)\n",
    "mode = 'test'\n",
    "\n",
    "# if mode == 'train':\n",
    "#     n_data = len(inferences[0].train_dataset)\n",
    "# elif mode == 'valid':\n",
    "#     n_data = len(inferences[0].valid_dataset)\n",
    "# elif mode == 'test':\n",
    "#     n_data = len(inferences[0].test_dataset)\n",
    "# else:\n",
    "#     raise(Exception(f\"{mode} is not supported\"))\n",
    "\n",
    "# classes = inferences[0].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf['save_path'] = os.path.join(conf['save_dir_path'], f\"{mode}_{conf['run_name']}.csv\")\n",
    "\n",
    "# filename_and_class = []\n",
    "# rles = []\n",
    "\n",
    "# for i in range(10): #range(n_data):\n",
    "#     outputs = None\n",
    "#     image_names = None\n",
    "\n",
    "#     for inference in inferences:\n",
    "#         if outputs is None:\n",
    "#             outputs, image_names = inference.inference(mode=mode, idx=i)\n",
    "#         else:\n",
    "#             new_outputs, new_image_names = inference.inference(mode=mode, idx=i)\n",
    "#             if new_image_names != image_names:\n",
    "#                 raise(Exception(\"Image names are different!\"))\n",
    "#             outputs += new_outputs\n",
    "\n",
    "#     outputs = outputs > n_models / 2\n",
    "\n",
    "#     if isinstance(image_names, str):\n",
    "#         image_names = (image_names, )\n",
    "\n",
    "#     for output, image_name in zip(outputs, image_names):\n",
    "#         for c, segm in enumerate(output):\n",
    "#             rle = encode_mask_to_rle(segm)\n",
    "#             rles.append(rle)\n",
    "#             filename_and_class.append(f\"{classes['idx2class'][c]}_{image_name}\")\n",
    "\n",
    "\n",
    "# classes, filename = zip(*[x.split(\"_\") for x in filename_and_class])\n",
    "# image_name = [os.path.basename(f) for f in filename]\n",
    "\n",
    "# df = pd.DataFrame({\n",
    "#     \"image_name\": image_name,\n",
    "#     \"class\": classes,\n",
    "#     \"rle\": rles,\n",
    "# })\n",
    "\n",
    "# df.to_csv(conf['save_path'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
