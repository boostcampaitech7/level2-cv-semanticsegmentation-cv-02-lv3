{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import sys\n",
    "from itertools import accumulate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "\n",
    "sys.path.append('../../')\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log(log_path):    \n",
    "    exp_path = log_path.replace('log.json', 'exp.json')\n",
    "    conf = utils.read_json(exp_path)\n",
    "    logs = utils.read_json(log_path)\n",
    "\n",
    "    epochs = [int(i) for i in logs['epoch'].keys()]\n",
    "    new_log = {'epoch': epochs}\n",
    "\n",
    "    for epoch in epochs:\n",
    "        log = logs['epoch'][str(epoch)]\n",
    "\n",
    "        for k, v in log.items():\n",
    "            if isinstance(v, dict):\n",
    "                prefix = k[:5]\n",
    "                for kk, vv in v.items():\n",
    "                    new_key = f'{prefix}_{kk}'\n",
    "                    new_log.setdefault(new_key, []).append(vv)\n",
    "\n",
    "            else:\n",
    "                new_log.setdefault(k, []).append(v)\n",
    "\n",
    "    runtime = [(x+y)/3600 for x, y in zip(new_log['train_run_time'], new_log['valid_run_time'])]\n",
    "    time = list(accumulate(runtime))\n",
    "    \n",
    "    new_log['time'] = time\n",
    "    new_log['max_train_dice'] = max(new_log['train_dice'])\n",
    "    new_log['max_valid_dice'] = max(new_log['valid_dice'])\n",
    "    new_log['max_valid_dice_index'] = new_log['valid_dice'].index(new_log['max_valid_dice'])\n",
    "    new_log['name'] = conf['run_name'] + f\"_vdice_{new_log['max_valid_dice']:.3f}\"\n",
    "\n",
    "    return new_log, conf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path1 = \"/data/ephemeral/home/Dongjin/level2-cv-semanticsegmentation-cv-02-lv3/Baseline/Dongjin/transformers_1119/trained_models/cont/mit-b2_cont_size_1024/log.json\"\n",
    "log_path2 = \"/data/ephemeral/home/Dongjin/level2-cv-semanticsegmentation-cv-02-lv3/Baseline/Dongjin/transformers_1120/trained_models/cont/mit-b2_cont_size_1024_cont_weight/log.json\"\n",
    "\n",
    "log_paths = [log_path1, log_path2]\n",
    "df = None\n",
    "\n",
    "for i, log_path in enumerate(log_paths):\n",
    "    log, _ = get_log(log_path)\n",
    "    name = log['name']\n",
    "    index = log['max_valid_dice_index']\n",
    "    \n",
    "    dicts = {}\n",
    "    dicts['name'] = [name]\n",
    "\n",
    "    for k, v in log.items():\n",
    "        if not isinstance(v, list): \n",
    "            continue\n",
    "        dicts[k] = [v[index]]\n",
    "\n",
    "    if df is None:\n",
    "        df = pd.DataFrame(dicts)\n",
    "    else:\n",
    "        df = pd.concat([df, pd.DataFrame(dicts)], ignore_index=True)\n",
    "\n",
    "df.to_csv('result.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
